# ğŸ§  Nodo di Chiamata Modello Grande
## â“ Cosa Ã¨ il Nodo di Chiamata Modello Grande?
Il nodo di chiamata modello grande Ã¨ il nodo core nel flusso di lavoro Magic Flow, permette di interagire direttamente con modelli di linguaggio di grandi dimensioni (come GPT-4, ecc.), utilizzato per generare contenuti testuali, rispondere a domande, analizzare contenuti o effettuare ragionamenti. In parole semplici, questo nodo Ã¨ come un ponte per dialogare con l'intelligenza artificiale sulla piattaforma Magic.

**Spiegazione Immagine:**

L'interfaccia del nodo di chiamata modello grande include aree di configurazione core come selezione modello, prompt di sistema, prompt utente, e opzioni di configurazione avanzate come regolazione parametri modello, configurazione knowledge base, ecc.
![Nodo Modello Grande](https://cdn.letsmagic.cn/static/img/Large-model.png)

## ğŸ¯ PerchÃ© Serve il Nodo di Chiamata Modello Grande?
Nel processo di costruzione di applicazioni intelligenti, il nodo di chiamata modello grande svolge il ruolo di "cervello", fornendo capacitÃ  di decisione intelligente e generazione contenuti per il flusso di lavoro:
- **Elaborazione Linguaggio Naturale**: Comprensione e generazione di linguaggio umano, permettendo all'applicazione di comunicare con gli utenti in modo naturale
- **Creazione Contenuti**: Generazione di copy, riassunti, traduzioni o altri contenuti creativi
- **Domande e Risposte Conoscenza**: Risposta a domande in campi professionali basate sulla knowledge base configurata
- **Ragionamento Logico**: Analisi informazioni e raggiungimento conclusioni, assistenza nella formulazione decisioni
- **Interazione Personalizzata**: Fornitura risposte personalizzate basate sulle esigenze utente e storico

## ğŸ“‹ Scenari Applicabili
### 1. ğŸ¤– Robot Assistente Clienti Intelligente
Progettare un robot assistente clienti capace di rispondere a consulenze prodotto, risolvere problemi utente, attraverso configurazione knowledge base professionale, fornire informazioni accurate sui prodotti e soluzioni.
### 2. âœï¸ Assistente Creazione Contenuti
Costruire un assistente capace di generare vari tipi di copy, riassunti o contenuti creativi, come copy marketing, descrizioni prodotto o post social media.
### 3. ğŸ“š Sistema Domande e Risposte Knowledge Base
Creare un sistema di domande e risposte basato su documenti interni aziendali, permettendo ai dipendenti di ottenere rapidamente informazioni professionali, migliorando l'efficienza lavorativa.
### 4. ğŸ“Š Analisi e Interpretazione Dati
Convertire risultati di analisi dati in spiegazioni di linguaggio naturale facilmente comprensibili, aiutando il personale non tecnico a comprendere dati complessi.

## âš™ï¸ Spiegazione Parametri Nodo
### Parametri Base
|Nome Parametro|Spiegazione|Obbligatorio|Valore Default|
|---|---|---|---|
|Modello|Selezione del modello di linguaggio da utilizzare, come GPT-4, Claude, ecc.|SÃ¬|gpt-4o-global|
|Strumenti|Configurazione capacitÃ  strumenti associati, permettere al modello di rispondere basandosi su conoscenze specifiche|||
|Impostazione Knowledge Base|Configurazione knowledge base associata, permettere al modello di rispondere basandosi su conoscenze specifiche|No|Nessuna|
|Prompt Sistema|Istruzioni di background per il modello, definizione ruolo e comportamento generale del modello|SÃ¬|Nessuno|
|Prompt Utente|Domanda specifica o istruzioni dell'utente|No|Nessuno|

### Configurazione Modello
|Nome Parametro|Spiegazione|Obbligatorio|Valore Default|
|---|---|---|---|
|Temperatura|Controllo casualitÃ  output, valore maggiore risposta piÃ¹ creativa, valore minore risposta piÃ¹ deterministica|No|0.5|
|Caricamento Automatico Memoria|Se abilitare funzione memoria automatica, ricordare storico conversazione|No|SÃ¬|
|Numero Massimo Memoria|QuantitÃ  massima messaggi storici da ricordare|No|50|
|Modello Comprensione Visiva|Nome modello grande per elaborazione immagini|No|Nessuno|
|Messaggi Storici|Impostazione messaggi conversazione storica, per costruire contesto dialogo|No|Nessuno|

### Contenuto Output
|Campo Output|Spiegazione|
|---|---|
|Risposta Modello Grande (response)|Contenuto risposta del modello grande, utilizzabile per mostrare all'utente o passare a nodi downstream|
|Strumenti Chiamati (tool_calls)|Informazioni strumenti chiamati dal modello, contenenti nome strumento, parametri, risultati, ecc.|

## ğŸ“– Istruzioni per l'Uso
### Passi di Configurazione Base
1. **Selezionare il Modello Appropriato**ï¼š
    1. Selezionare il modello di linguaggio grande corrispondente in base alle esigenze
    2. Per compiti generali Ã¨ possibile selezionare modelli ordinari, per compiti complessi selezionare modelli avanzati come GPT-4
2. **Scrivere il Prompt di Sistema**ï¼š
    1. Definire chiaramente il ruolo del modello, come "Sei un addetto al servizio clienti"
    2. Impostare lo stile e l'ambito delle risposte
    3. Informare il modello sulle risorse o strumenti utilizzabili
3. **Configurare il Prompt Utente**ï¼š
    1. Ãˆ possibile inserire direttamente domande o istruzioni fisse
    2. Ãˆ anche possibile utilizzare riferimenti variabili per contenuti dinamici, come `{{user_message}}` per fare riferimento all'input effettivo dell'utente
4. **Impostare i Parametri del Modello**ï¼š
    1. Regolare la temperatura per controllare la creativitÃ  o accuratezza delle risposte
    2. Impostare se abilitare la memoria automatica e la quantitÃ  di record storici
5. **Configurare la Knowledge Base (Opzionale)**ï¼š
    1. Selezionare la knowledge base da associare
    2. Impostare la soglia di similaritÃ  e il numero di risultati di ricerca

### Tecniche Avanzate
#### Ottimizzazione Prompt
Scrivere prompt di alta qualitÃ  Ã¨ la chiave per utilizzare efficacemente i modelli grandiï¼š
1. **Essere Specifico e Chiaro**ï¼šEsprimere chiaramente le proprie aspettative e esigenze
2. **Impostazione Ruolo**ï¼šAssegnare al modello una posizione di ruolo chiara nel prompt di sistema
3. **Suddivisione Passi**ï¼šGuidare il modello a pensare per passi su problemi complessi

#### Collaborazione con Altri Nodi
1. **In Combinazione con il Nodo Risposta Messaggio**ï¼š
    1. Mostrare all'utente l'output generato dal modello grande attraverso il nodo risposta messaggio
    2. Impostare il prompt utente come vuoto, permettendo al messaggio dell'utente di diventare automaticamente l'input
2. **In Combinazione con il Nodo Ramo Condizionale**ï¼š
    1. Utilizzare il nodo riconoscimento intento per analizzare l'intento dell'utente
    2. Dirigere verso diversi flussi di elaborazione in base a diversi intenti
3. **In Combinazione con il Nodo Recupero Conoscenza**ï¼š
    1. Utilizzare prima il nodo recupero conoscenza per ottenere informazioni rilevanti
    2. Fornire poi i risultati della ricerca come contesto al modello grande

## âš ï¸ Note di Attenzione
### Limitazioni Token
Ogni modello ha un limite massimo di token elaborabili, superarlo causerÃ  erroriï¼š
- GPT-3.5ï¼šSupporta al massimo 16K tokens
- GPT-4ï¼šSupporta al massimo 128K tokens
- Claudeï¼šSupporta al massimo 200K tokens

*<font color="#CE2B2E">Suggerimentoï¼šCirca 1 carattere cinese â‰ˆ 1.5-2 tokens, 1 parola inglese â‰ˆ 1-2 tokens</font>*

### AggiornabilitÃ  delle Conoscenze
Le conoscenze dei modelli grandi hanno una data di cutoff dell'addestramento, potrebbero non conoscere le informazioni piÃ¹ recenti, si consigliaï¼š
- Per scenari che richiedono informazioni aggiornate, considerare l'utilizzo combinato del nodo richiesta HTTP per ottenere dati in tempo reale
- O aggiornare regolarmente le ultime informazioni attraverso la knowledge base

### Gestione Informazioni Sensibili
I modelli grandi potrebbero elaborare informazioni fornite dagli utenti, prestare attenzioneï¼š
- Evitare di includere informazioni riservate o sensibili nei prompt
- Per dati che necessitano di riservatezza, si consiglia di utilizzare la knowledge base invece dell'input diretto

## â“ Domande Frequenti
### Domanda 1: Cosa fare se il contenuto della risposta del modello grande non corrisponde alle aspettative?
**Soluzioni**ï¼šPotrebbe essere che il prompt non sia abbastanza chiaro. Provareï¼š
- Modificare il prompt di sistema, definire piÃ¹ specificamente il compito e le aspettative
- Aggiungere esempi, mostrare la modalitÃ  di domanda e risposta ideale
- Regolare il parametro temperatura, abbassare la temperatura per rendere la risposta piÃ¹ deterministica

### Domanda 2: Come gestire domande professionali che il modello grande non riesce a rispondere?
**Soluzioni**ï¼šIl modello grande dipende dai dati di addestramento, potrebbe avere conoscenze limitate in campi specificiï¼š
- Configurare una knowledge base professionale, fornire supporto di conoscenze di settore
- Aggiungere conoscenze di background necessarie nel prompt di sistema
- Utilizzare l'istruzione "se non si trova informazione, informare chiaramente" per evitare di inventare risposte

### Domanda 3: Cosa fare se l'esecuzione del nodo chiamata modello grande Ã¨ lenta?
**Soluzioni**ï¼šI fattori che influenzano la velocitÃ  sono moltepliciï¼š
- Provare a utilizzare modelli con risposta piÃ¹ veloce (come GPT-3.5 al posto di GPT-4)
- Ridurre la quantitÃ  di messaggi storici, diminuire il carico di elaborazione
- Ottimizzare il prompt, renderlo piÃ¹ conciso e chiaro

## ğŸŒŸ Migliori Pratiche
### Nodi di Combinazione Comuni
|Tipo di Nodo|Motivo di Combinazione|
|---|---|
|Nodo Risposta Messaggio|Inviare all'utente il contenuto generato dal modello grande|
|Nodo Ramo Condizionale|Decidere l'operazione successiva in base all'output del modello grande|
|Nodo Recupero Conoscenza|Fornire supporto di conoscenze professionali|
|Nodo Query Messaggi Storici|Fornire contesto di conversazione, migliorare la coerenza|
|Nodo Salvataggio Variabili|Salvare informazioni importanti per l'utilizzo nei flussi successivi|

---

# å¤§æ¨¡å‹è°ƒç”¨èŠ‚ç‚¹
## ä»€ä¹ˆæ˜¯å¤§æ¨¡å‹è°ƒç”¨èŠ‚ç‚¹ï¼Ÿ
å¤§æ¨¡å‹è°ƒç”¨èŠ‚ç‚¹æ˜¯Magic Flowå·¥ä½œæµä¸­çš„æ ¸å¿ƒèŠ‚ç‚¹ï¼Œå®ƒå…è®¸æ‚¨ç›´æ¥ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆå¦‚GPT-4ç­‰ï¼‰è¿›è¡Œäº¤äº’ï¼Œç”¨äºç”Ÿæˆæ–‡æœ¬å†…å®¹ã€å›ç­”é—®é¢˜ã€åˆ†æå†…å®¹æˆ–è¿›è¡Œæ¨ç†ã€‚ç®€å•æ¥è¯´ï¼Œè¿™ä¸ªèŠ‚ç‚¹å°±åƒæ˜¯æ‚¨åœ¨Magicå¹³å°ä¸Šä¸äººå·¥æ™ºèƒ½å¯¹è¯çš„æ¡¥æ¢ã€‚

**å›¾ç‰‡è¯´æ˜ï¼š**

å¤§æ¨¡å‹è°ƒç”¨èŠ‚ç‚¹ç•Œé¢åŒ…æ‹¬æ¨¡å‹é€‰æ‹©ã€ç³»ç»Ÿæç¤ºè¯ã€ç”¨æˆ·æç¤ºè¯ç­‰æ ¸å¿ƒé…ç½®åŒºåŸŸï¼Œä»¥åŠé«˜çº§é…ç½®é€‰é¡¹å¦‚æ¨¡å‹å‚æ•°è°ƒæ•´ã€çŸ¥è¯†åº“é…ç½®ç­‰ã€‚
![å¤§æ¨¡å‹è°ƒç”¨èŠ‚ç‚¹](https://cdn.letsmagic.cn/static/img/Large-model.png)

## ä¸ºä»€ä¹ˆéœ€è¦å¤§æ¨¡å‹è°ƒç”¨èŠ‚ç‚¹ï¼Ÿ
åœ¨æ™ºèƒ½åº”ç”¨çš„æ„å»ºè¿‡ç¨‹ä¸­ï¼Œå¤§æ¨¡å‹è°ƒç”¨èŠ‚ç‚¹å……å½“"å¤§è„‘"çš„è§’è‰²ï¼Œä¸ºæ‚¨çš„å·¥ä½œæµæä¾›æ™ºèƒ½å†³ç­–å’Œå†…å®¹ç”Ÿæˆèƒ½åŠ›ï¼š
- **è‡ªç„¶è¯­è¨€å¤„ç†**ï¼šç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€ï¼Œä½¿åº”ç”¨èƒ½å¤Ÿä»¥è‡ªç„¶æ–¹å¼ä¸ç”¨æˆ·äº¤æµ
- **å†…å®¹åˆ›ä½œ**ï¼šç”Ÿæˆæ–‡æ¡ˆã€æ‘˜è¦ã€ç¿»è¯‘æˆ–å…¶ä»–åˆ›æ„å†…å®¹
- **çŸ¥è¯†é—®ç­”**ï¼šæ ¹æ®é…ç½®çš„çŸ¥è¯†åº“å›ç­”ä¸“ä¸šé¢†åŸŸé—®é¢˜
- **é€»è¾‘æ¨ç†**ï¼šåˆ†æä¿¡æ¯å¹¶å¾—å‡ºç»“è®ºï¼ŒååŠ©å†³ç­–åˆ¶å®š
- **ä¸ªæ€§åŒ–äº¤äº’**ï¼šæ ¹æ®ç”¨æˆ·éœ€æ±‚å’Œå†å²è®°å½•æä¾›å®šåˆ¶åŒ–çš„å›å¤
## é€‚ç”¨åœºæ™¯
### 1. æ™ºèƒ½å®¢æœæœºå™¨äºº
è®¾è®¡ä¸€ä¸ªèƒ½å¤Ÿå›ç­”äº§å“å’¨è¯¢ã€è§£å†³ç”¨æˆ·é—®é¢˜çš„å®¢æœæœºå™¨äººï¼Œé€šè¿‡é…ç½®ä¸“ä¸šçŸ¥è¯†åº“ï¼Œæä¾›å‡†ç¡®çš„äº§å“ä¿¡æ¯å’Œè§£å†³æ–¹æ¡ˆã€‚
### 2. å†…å®¹åˆ›ä½œåŠ©æ‰‹
æ„å»ºä¸€ä¸ªèƒ½å¤Ÿç”Ÿæˆå„ç±»æ–‡æ¡ˆã€æ‘˜è¦æˆ–åˆ›æ„å†…å®¹çš„åŠ©æ‰‹ï¼Œå¦‚è¥é”€æ–‡æ¡ˆã€äº§å“æè¿°æˆ–ç¤¾äº¤åª’ä½“å¸–å­ã€‚
### 3. çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ
åˆ›å»ºåŸºäºä¼ä¸šå†…éƒ¨æ–‡æ¡£çš„é—®ç­”ç³»ç»Ÿï¼Œè®©å‘˜å·¥èƒ½å¿«é€Ÿè·å–ä¸“ä¸šä¿¡æ¯ï¼Œæé«˜å·¥ä½œæ•ˆç‡ã€‚
### 4. æ•°æ®åˆ†æä¸è§£è¯»
å°†æ•°æ®åˆ†æç»“æœè½¬åŒ–ä¸ºæ˜“äºç†è§£çš„è‡ªç„¶è¯­è¨€è§£é‡Šï¼Œå¸®åŠ©éæŠ€æœ¯äººå‘˜ç†è§£å¤æ‚æ•°æ®ã€‚
## èŠ‚ç‚¹å‚æ•°è¯´æ˜
### åŸºæœ¬å‚æ•°
|å‚æ•°åç§°|è¯´æ˜|æ˜¯å¦å¿…å¡«|é»˜è®¤å€¼|
|---|---|---|---|
|æ¨¡å‹|é€‰æ‹©è¦ä½¿ç”¨çš„å¤§è¯­è¨€æ¨¡å‹ï¼Œå¦‚GPT-4ã€Claudeç­‰|æ˜¯|gpt-4o-global|
|å·¥å…·|é…ç½®å…³è”çš„å·¥å…·èƒ½åŠ›ï¼Œè®©æ¨¡å‹åŸºäºç‰¹å®šçŸ¥è¯†å›ç­”|||  
|çŸ¥è¯†åº“è®¾ç½®|é…ç½®å…³è”çš„çŸ¥è¯†åº“ï¼Œè®©æ¨¡å‹åŸºäºç‰¹å®šçŸ¥è¯†å›ç­”|å¦|æ— |
|ç³»ç»Ÿæç¤ºè¯|ç»™æ¨¡å‹çš„èƒŒæ™¯æŒ‡ä»¤ï¼Œå®šä¹‰æ¨¡å‹çš„è§’è‰²å’Œæ•´ä½“è¡Œä¸º|æ˜¯|æ— |
|ç”¨æˆ·æç¤ºè¯|ç”¨æˆ·çš„å…·ä½“é—®é¢˜æˆ–æŒ‡ä»¤|å¦|æ— |

### æ¨¡å‹é…ç½®
|å‚æ•°åç§°|è¯´æ˜|æ˜¯å¦å¿…å¡«|é»˜è®¤å€¼|
|---|---|---|---|
|æ¸©åº¦|æ§åˆ¶è¾“å‡ºçš„éšæœºæ€§ï¼Œå€¼è¶Šå¤§å›ç­”è¶Šå…·åˆ›é€ æ€§ï¼Œå€¼è¶Šå°å›ç­”è¶Šç¡®å®šæ€§|å¦|0.5|
|è‡ªåŠ¨åŠ è½½è®°å¿†|æ˜¯å¦å¯ç”¨è‡ªåŠ¨è®°å¿†åŠŸèƒ½ï¼Œè®°ä½å¯¹è¯å†å²|å¦|æ˜¯|
|æœ€å¤§è®°å¿†æ¡æ•°|è®°å¿†çš„æœ€å¤§å†å²æ¶ˆæ¯æ•°é‡|å¦|50|
|è§†è§‰ç†è§£æ¨¡å‹|ç”¨äºå¤„ç†å›¾åƒçš„å¤§æ¨¡å‹åç§°|å¦|æ— |
|å†å²æ¶ˆæ¯|è®¾ç½®å†å²å¯¹è¯æ¶ˆæ¯ï¼Œç”¨äºæ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡|å¦|æ— |

### è¾“å‡ºå†…å®¹
|è¾“å‡ºå­—æ®µ|è¯´æ˜|
|---|---|
|å¤§æ¨¡å‹å“åº”ï¼ˆresponseï¼‰|å¤§æ¨¡å‹çš„å›å¤å†…å®¹ï¼Œå¯ç”¨äºæ˜¾ç¤ºç»™ç”¨æˆ·æˆ–ä¼ é€’ç»™ä¸‹æ¸¸èŠ‚ç‚¹|
|è°ƒç”¨è¿‡çš„å·¥å…·ï¼ˆtool_callsï¼‰|æ¨¡å‹è°ƒç”¨çš„å·¥å…·ä¿¡æ¯ï¼ŒåŒ…å«å·¥å…·åç§°ã€å‚æ•°ã€ç»“æœç­‰|

## ä½¿ç”¨è¯´æ˜
### åŸºæœ¬é…ç½®æ­¥éª¤
1. **é€‰æ‹©åˆé€‚çš„æ¨¡å‹**ï¼š
    1. æ ¹æ®éœ€æ±‚é€‰æ‹©ç›¸åº”çš„å¤§è¯­è¨€æ¨¡å‹
    2. ä¸€èˆ¬ä»»åŠ¡å¯é€‰æ‹©æ™®é€šæ¨¡å‹ï¼Œå¤æ‚ä»»åŠ¡å¯é€‰æ‹©é«˜çº§æ¨¡å‹å¦‚GPT-4
2. **ç¼–å†™ç³»ç»Ÿæç¤ºè¯**ï¼š
    1. æ˜ç¡®å®šä¹‰æ¨¡å‹çš„è§’è‰²ï¼Œå¦‚"ä½ æ˜¯ä¸€ä½å®¢æœä¸“å‘˜"
    2. è®¾å®šå›ç­”çš„é£æ ¼å’ŒèŒƒå›´
    3. å‘ŠçŸ¥æ¨¡å‹å¯ä»¥ä½¿ç”¨çš„èµ„æºæˆ–å·¥å…·
3. **é…ç½®ç”¨æˆ·æç¤ºè¯**ï¼š
    1. å¯ç›´æ¥è¾“å…¥å›ºå®šçš„é—®é¢˜æˆ–æŒ‡ä»¤
    2. ä¹Ÿå¯ä½¿ç”¨å˜é‡å¼•ç”¨åŠ¨æ€å†…å®¹ï¼Œå¦‚`{{user_message}}`å¼•ç”¨ç”¨æˆ·çš„å®é™…è¾“å…¥
4. **è®¾ç½®æ¨¡å‹å‚æ•°**ï¼š
    1. è°ƒæ•´æ¸©åº¦ä»¥æ§åˆ¶å›ç­”çš„åˆ›é€ æ€§æˆ–å‡†ç¡®æ€§
    2. è®¾ç½®æ˜¯å¦å¯ç”¨è‡ªåŠ¨è®°å¿†å’Œå†å²è®°å½•æ•°é‡
5. **é…ç½®çŸ¥è¯†åº“ï¼ˆå¯é€‰ï¼‰**ï¼š
    1. é€‰æ‹©è¦å…³è”çš„çŸ¥è¯†åº“
    2. è®¾ç½®ç›¸ä¼¼åº¦é˜ˆå€¼å’Œæœç´¢ç»“æœæ•°é‡
### è¿›é˜¶æŠ€å·§
#### æç¤ºè¯ä¼˜åŒ–
ç¼–å†™é«˜è´¨é‡çš„æç¤ºè¯æ˜¯æœ‰æ•ˆä½¿ç”¨å¤§æ¨¡å‹çš„å…³é”®ï¼š
1. **æ˜ç¡®å…·ä½“**ï¼šæ¸…æ™°è¡¨è¾¾æ‚¨çš„æœŸæœ›å’Œéœ€æ±‚
2. **è§’è‰²è®¾å®š**ï¼šåœ¨ç³»ç»Ÿæç¤ºè¯ä¸­ç»™æ¨¡å‹æ˜ç¡®çš„è§’è‰²å®šä½
3. **æ­¥éª¤æ‹†åˆ†**ï¼šå¼•å¯¼æ¨¡å‹æŒ‰æ­¥éª¤æ€è€ƒå¤æ‚é—®é¢˜
#### ä¸å…¶ä»–èŠ‚ç‚¹ååŒ
1. **æ­é…æ¶ˆæ¯å›å¤èŠ‚ç‚¹**ï¼š
    1. å°†å¤§æ¨¡å‹çš„è¾“å‡ºé€šè¿‡æ¶ˆæ¯å›å¤èŠ‚ç‚¹å±•ç¤ºç»™ç”¨æˆ·
    2. è®¾ç½®ç”¨æˆ·æç¤ºè¯ä¸ºç©ºï¼Œè®©ç”¨æˆ·çš„æ¶ˆæ¯è‡ªåŠ¨ä½œä¸ºè¾“å…¥
2. **ç»“åˆæ¡ä»¶åˆ†æ”¯èŠ‚ç‚¹**ï¼š
    1. ä½¿ç”¨æ„å›¾è¯†åˆ«èŠ‚ç‚¹åˆ†æç”¨æˆ·æ„å›¾
    2. æ ¹æ®ä¸åŒæ„å›¾è½¬å‘ä¸åŒçš„å¤„ç†æµç¨‹
3. **é…åˆçŸ¥è¯†æ£€ç´¢èŠ‚ç‚¹**ï¼š
    1. å…ˆä½¿ç”¨çŸ¥è¯†æ£€ç´¢è·å–ç›¸å…³ä¿¡æ¯
    2. å†å°†æ£€ç´¢ç»“æœä½œä¸ºä¸Šä¸‹æ–‡æä¾›ç»™å¤§æ¨¡å‹
## æ³¨æ„äº‹é¡¹
### Tokené™åˆ¶
æ¯ä¸ªæ¨¡å‹éƒ½æœ‰æœ€å¤§tokenå¤„ç†é™åˆ¶ï¼Œè¶…å‡ºé™åˆ¶ä¼šå¯¼è‡´é”™è¯¯ï¼š
- GPT-3.5ï¼šæœ€å¤šæ”¯æŒ16K tokens
- GPT-4ï¼šæœ€å¤šæ”¯æŒ128K tokens
- Claudeï¼šæœ€å¤šæ”¯æŒ200K tokens

*<font color="#CE2B2E">æç¤ºï¼šå¤§çº¦1ä¸ªæ±‰å­—â‰ˆ1.5-2ä¸ªtokensï¼Œ1ä¸ªè‹±æ–‡å•è¯â‰ˆ1-2ä¸ªtokens</font>*
### çŸ¥è¯†æ—¶æ•ˆæ€§
å¤§æ¨¡å‹çš„çŸ¥è¯†æœ‰è®­ç»ƒæˆªæ­¢æ—¥æœŸï¼Œå¯¹äºæœ€æ–°ä¿¡æ¯å¯èƒ½ä¸äº†è§£ï¼Œå»ºè®®ï¼š
- å¯¹äºéœ€è¦æœ€æ–°ä¿¡æ¯çš„åœºæ™¯ï¼Œè€ƒè™‘ç»“åˆHTTPè¯·æ±‚èŠ‚ç‚¹è·å–å®æ—¶æ•°æ®
- æˆ–é€šè¿‡çŸ¥è¯†åº“å®šæœŸæ›´æ–°æœ€æ–°ä¿¡æ¯
### æ•æ„Ÿä¿¡æ¯å¤„ç†
å¤§æ¨¡å‹å¯èƒ½ä¼šå¤„ç†ç”¨æˆ·æä¾›çš„ä¿¡æ¯ï¼Œæ³¨æ„ï¼š
- é¿å…åœ¨æç¤ºè¯ä¸­åŒ…å«æœºå¯†æˆ–æ•æ„Ÿä¿¡æ¯
- å¯¹äºéœ€ä¿å¯†çš„æ•°æ®ï¼Œå»ºè®®ä½¿ç”¨çŸ¥è¯†åº“è€Œéç›´æ¥è¾“å…¥
## å¸¸è§é—®é¢˜
### é—®é¢˜1ï¼šå¤§æ¨¡å‹å›å¤å†…å®¹ä¸ç¬¦åˆé¢„æœŸæ€ä¹ˆåŠï¼Ÿ
**è§£å†³æ–¹æ¡ˆ**ï¼šå¯èƒ½æ˜¯æç¤ºè¯ä¸å¤Ÿæ˜ç¡®ã€‚å°è¯•ï¼š
- ä¿®æ”¹ç³»ç»Ÿæç¤ºè¯ï¼Œæ›´å…·ä½“åœ°å®šä¹‰ä»»åŠ¡å’ŒæœŸæœ›
- å¢åŠ ç¤ºä¾‹ï¼Œå±•ç¤ºç†æƒ³çš„é—®ç­”æ¨¡å¼
- è°ƒæ•´æ¸©åº¦å‚æ•°ï¼Œé™ä½æ¸©åº¦ä½¿å›ç­”æ›´ç¡®å®šæ€§
### é—®é¢˜2ï¼šå¦‚ä½•å¤„ç†å¤§æ¨¡å‹æ— æ³•å›ç­”çš„ä¸“ä¸šé—®é¢˜ï¼Ÿ
**è§£å†³æ–¹æ¡ˆ**ï¼šå¤§æ¨¡å‹ä¾èµ–è®­ç»ƒæ•°æ®ï¼Œå¯¹ç‰¹å®šé¢†åŸŸå¯èƒ½çŸ¥è¯†æœ‰é™ï¼š
- é…ç½®ä¸“ä¸šçŸ¥è¯†åº“ï¼Œæä¾›é¢†åŸŸçŸ¥è¯†æ”¯æŒ
- åœ¨ç³»ç»Ÿæç¤ºè¯ä¸­åŠ å…¥å¿…è¦çš„èƒŒæ™¯çŸ¥è¯†
- ä½¿ç”¨"æŸ¥æ— ä¿¡æ¯åˆ™æ˜ç¡®å‘ŠçŸ¥"çš„æŒ‡ä»¤ï¼Œé¿å…ç¼–é€ ç­”æ¡ˆ
### é—®é¢˜3ï¼šå¤§æ¨¡å‹è°ƒç”¨èŠ‚ç‚¹æ‰§è¡Œå¾ˆæ…¢æ€ä¹ˆåŠï¼Ÿ
**è§£å†³æ–¹æ¡ˆ**ï¼šå½±å“é€Ÿåº¦çš„å› ç´ æœ‰å¤šç§ï¼š
- å°è¯•ä½¿ç”¨å“åº”æ›´å¿«çš„æ¨¡å‹ï¼ˆå¦‚GPT-3.5æ›¿ä»£GPT-4ï¼‰
- å‡å°‘å†å²æ¶ˆæ¯æ•°é‡ï¼Œé™ä½å¤„ç†è´Ÿæ‹…
- ä¼˜åŒ–æç¤ºè¯ï¼Œä½¿æŒ‡ä»¤æ›´ç®€æ´æ˜ç¡®
## æœ€ä½³å®è·µ
### å¸¸è§æ­é…èŠ‚ç‚¹
|**èŠ‚ç‚¹ç±»å‹**|**æ­é…åŸå› **|
|---|---|
|æ¶ˆæ¯å›å¤èŠ‚ç‚¹|å°†å¤§æ¨¡å‹ç”Ÿæˆçš„å†…å®¹å‘é€ç»™ç”¨æˆ·|
|æ¡ä»¶åˆ†æ”¯èŠ‚ç‚¹|æ ¹æ®å¤§æ¨¡å‹çš„è¾“å‡ºå†³å®šä¸‹ä¸€æ­¥æ“ä½œ|
|çŸ¥è¯†æ£€ç´¢èŠ‚ç‚¹|æä¾›ä¸“ä¸šé¢†åŸŸçŸ¥è¯†æ”¯æŒ|
|å†å²æ¶ˆæ¯æŸ¥è¯¢|æä¾›å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œå¢å¼ºè¿è´¯æ€§|
|å˜é‡ä¿å­˜èŠ‚ç‚¹|ä¿å­˜é‡è¦ä¿¡æ¯ä¾›åç»­æµç¨‹ä½¿ç”¨|